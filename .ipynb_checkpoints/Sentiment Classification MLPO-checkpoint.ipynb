{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "filename= \"Export_loop-sentiment-pos-neg-train_05112020000000.csv\"\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>No one cares about marketing slides - a techni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Are all three hosts providing storage/capacity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>would loved to had managed to get down to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Vending machine at work is out of Dasani water...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @VMwareEdu: Paul Maritz, CEO and President ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Had few folks ask, if you're interested Johnny...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Get notified of the latest #vSAN patch release...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Negative</td>\n",
       "      <td>End of general support is 3/12/2020.  6.5 and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Placed 4th in funrun today in the 17-39 age gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Yup! Guys being currently under NDA know this ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0  Negative  No one cares about marketing slides - a techni...\n",
       "1  Positive  Are all three hosts providing storage/capacity...\n",
       "2  Negative  would loved to had managed to get down to the ...\n",
       "3  Negative  Vending machine at work is out of Dasani water...\n",
       "4  Positive  RT @VMwareEdu: Paul Maritz, CEO and President ...\n",
       "5  Positive  Had few folks ask, if you're interested Johnny...\n",
       "6  Positive  Get notified of the latest #vSAN patch release...\n",
       "7  Negative  End of general support is 3/12/2020.  6.5 and ...\n",
       "8  Negative  Placed 4th in funrun today in the 17-39 age gr...\n",
       "9  Positive  Yup! Guys being currently under NDA know this ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jdeshpande/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data cleaning and preprocessing\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmitization and stop word removal\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "for i in range(0, len(df)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', df['text'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the TF-IDF model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv = TfidfVectorizer()\n",
    "X = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.get_dummies(df['label'])\n",
    "y=y.iloc[:,1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Score:  0.7228070175438597\n"
     ]
    }
   ],
   "source": [
    "# Training model using Naive bayes classifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "spam_detect_model = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "y_pred=spam_detect_model.predict(X_test)\n",
    "\n",
    "\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(\"Naive Bayes Score: \", acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-Linear Score:  0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Training model using SVM classifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='linear').fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(\"SVM-Linear Score: \", acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7263157894736842\n"
     ]
    }
   ],
   "source": [
    "# Training model using Random forest classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfcl = RandomForestClassifier(n_estimators=100, random_state=50, bootstrap=False)\n",
    "rfcl = rfcl.fit(X_train, y_train)\n",
    "pred_RF = rfcl.predict(X_test)\n",
    "acc_RF = accuracy_score(y_test, pred_RF)\n",
    "print(acc_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score:  0.756140350877193\n"
     ]
    }
   ],
   "source": [
    "# Training model using Linear classifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='multinomial').fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression Score: \", acc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN - LSTM Model\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(df['text'],y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "max_len = 500\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X_train)\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,500,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 500, 500)          500000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                144640    \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 661,537\n",
      "Trainable params: 661,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1064 samples, validate on 266 samples\n",
      "Epoch 1/10\n",
      "1064/1064 [==============================] - 6s 6ms/step - loss: 0.6789 - accuracy: 0.5808 - val_loss: 0.6880 - val_accuracy: 0.5677\n",
      "Epoch 2/10\n",
      "1064/1064 [==============================] - 5s 5ms/step - loss: 0.5635 - accuracy: 0.7293 - val_loss: 0.5786 - val_accuracy: 0.6992\n",
      "Epoch 3/10\n",
      "1064/1064 [==============================] - 5s 5ms/step - loss: 0.4058 - accuracy: 0.8421 - val_loss: 0.6362 - val_accuracy: 0.6805\n",
      "Epoch 4/10\n",
      "1064/1064 [==============================] - 6s 5ms/step - loss: 0.3151 - accuracy: 0.8731 - val_loss: 0.6352 - val_accuracy: 0.6880\n",
      "Epoch 5/10\n",
      " 640/1064 [=================>............] - ETA: 1s - loss: 0.2263 - accuracy: 0.9141"
     ]
    }
   ],
   "source": [
    "model.fit(sequences_matrix,Y_train,batch_size=128,epochs=10,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
